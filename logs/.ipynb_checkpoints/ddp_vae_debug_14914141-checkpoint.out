[2025-07-14 15:13:58] Starting SLURM job 14914141 on clara05.sc.uni-leipzig.de
[2025-07-14 15:13:58] Job parameters: 2 tasks, 2 GPUs, 1 nodes
[2025-07-14 15:13:58] Loading required modules...
[2025-07-14 15:14:00] Activating conda environment...
[2025-07-14 15:14:00] Verifying environment...
Python 3.10.18
PyTorch version: 2.7.1+cu126
CUDA available: True
CUDA devices: 2
[2025-07-14 15:14:09] Checking training script...
[2025-07-14 15:14:09] Training script found: -rw-r--r-- 1 ci72buri sc_users 20145 Jul 14 15:13 train_vae.py
[2025-07-14 15:14:09] Testing training script import...
Training script import: SUCCESS
[2025-07-14 15:14:16] Checking required modules...
torch: OK
torch.distributed: OK
numpy: OK
wandb: OK
All required modules available
[2025-07-14 15:14:20] Configuring NCCL settings...
[2025-07-14 15:14:20] Setting up distributed training configuration...
[2025-07-14 15:14:20] Distributed training configuration:
[2025-07-14 15:14:20]   MASTER_ADDR: 172.26.10.5
[2025-07-14 15:14:20]   MASTER_PORT: 19144
[2025-07-14 15:14:20]   WORLD_SIZE: 2
[2025-07-14 15:14:20]   NODE_RANK: 0
[2025-07-14 15:14:20]   SLURM_GPUS_ON_NODE: 2
[2025-07-14 15:14:20]   SLURM_JOB_NUM_NODES: 1
[2025-07-14 15:14:20] Testing network connectivity...
PING 172.26.10.5 (172.26.10.5) 56(84) bytes of data.
64 bytes from 172.26.10.5: icmp_seq=1 ttl=64 time=0.055 ms

--- 172.26.10.5 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 0.055/0.055/0.055/0.000 ms
[2025-07-14 15:14:20] Testing GPU availability...
Mon Jul 14 15:14:20 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  Tesla V100-PCIE-32GB           On  | 00000000:05:00.0 Off |                    0 |
| N/A   27C    P0              24W / 250W |      0MiB / 32768MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE-32GB           On  | 00000000:43:00.0 Off |                    0 |
| N/A   24C    P0              25W / 250W |      0MiB / 32768MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
[2025-07-14 15:14:21] Checking torchrun availability...
/home/sc.uni-leipzig.de/ci72buri/.conda/envs/cell-vae/bin/torchrun
usage: torchrun [-h] [--nnodes NNODES] [--nproc-per-node NPROC_PER_NODE] [--rdzv-backend RDZV_BACKEND] [--rdzv-endpoint RDZV_ENDPOINT] [--rdzv-id RDZV_ID] [--rdzv-conf RDZV_CONF] [--standalone] [--max-restarts MAX_RESTARTS] [--monitor-interval MONITOR_INTERVAL] [--start-method {spawn,fork,forkserver}] [--role ROLE] [-m] [--no-python] [--run-path] [--log-dir LOG_DIR]
                [-r REDIRECTS] [-t TEE] [--local-ranks-filter LOCAL_RANKS_FILTER] [--node-rank NODE_RANK] [--master-addr MASTER_ADDR] [--master-port MASTER_PORT] [--local-addr LOCAL_ADDR] [--logs-specs LOGS_SPECS]
                training_script ...

Torch Distributed Elastic Training Launcher
[2025-07-14 15:14:23] Testing basic torchrun functionality...
