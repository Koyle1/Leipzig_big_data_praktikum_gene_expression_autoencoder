#!/bin/bash
#SBATCH --job-name=ddptrain
#SBATCH --ntasks=5
#SBATCH --gres=gpu:5
#SBATCH --cpus-per-task=4
#SBATCH --nodes=1
#SBATCH --output=logs/%x%j.out
#SBATCH --partition=paula
#SBATCH --mem=64G

module load Anaconda3
module load CUDA/12.6.0

eval "$(conda shell.bash hook)"
conda activate cell-vae

export NCCL_SOCKET_IFNAME=bond0
export GLOO_SOCKET_IFNAME=bond0
export NCCL_DEBUG=INFO
export NCCL_IB_DISABLE=1
export NCCL_P2P_DISABLE=1
export NCCL_USE_V4ONLY=1
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

PORT=$(shuf -i 10000-65000 -n 1)
MASTER_HOSTNAME=$(scontrol show hostname $SLURM_NODELIST | head -n 1)
MASTER_ADDR=$(getent hosts $MASTER_HOSTNAME | awk '{ print $1 }')
export MASTER_ADDR
export MASTER_PORT=$PORT

echo "MASTER_ADDR is $MASTER_ADDR"
ping -c 1 $MASTER_ADDR

torchrun \
  --nproc_per_node=5 \
  --nnodes=$SLURM_JOB_NUM_NODES \
  --node_rank=$SLURM_NODEID \
  --rdzv_backend=c10d \
  --rdzv_endpoint=$MASTER_ADDR:$MASTER_PORT \
  train_vae.py -- --config modelconfigs/example.yaml