{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Variational Autoencoder for Single Cell Transcriptomics in the CELLxGENE Dataset\n",
    "\n",
    "## Background\n",
    "\n",
    "### Dataset\n",
    "\n",
    "### Variational autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoCell.data_loader import SingleCellDataset\n",
    "import src\n",
    "import cellxgene_census\n",
    "import anndata\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The \"stable\" release is currently 2025-01-30. Specify 'census_version=\"2025-01-30\"' in future calls to open_soma() to ensure data consistency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 0 × 61888\n",
      "    obs: 'cell_type', 'tissue', 'disease', 'tissue_general', 'is_primary_data'\n",
      "    var: 'soma_joinid', 'feature_id', 'feature_name', 'feature_type', 'feature_length', 'nnz', 'n_measured_obs'\n"
     ]
    }
   ],
   "source": [
    "with cellxgene_census.open_soma() as census:\n",
    "    adata = cellxgene_census.get_anndata(\n",
    "        census, \n",
    "        \"Homo sapiens\",\n",
    "        obs_coords=slice(0, 100),\n",
    "        obs_value_filter=\"tissue_general == 'lung' and disease in ['normal','lung adenocarcinoma', 'squamous cell lung carcinoma', 'small cell lung carcinoma', 'non-small cell lung carcinoma', 'pleomorphic carcinoma', 'lung large cell carcinoma'] and is_primary_data == True\",  # Specific tissue\n",
    "        # var_value_filter=\"feature_name in ['GAPDH', 'ACTB']\",  # Specific genes\n",
    "        obs_column_names=[\"cell_type\", \"tissue\", \"disease\"]  # Minimal metadata\n",
    "    )\n",
    "\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frederik/Repositories/environments/math_ml/lib/python3.11/site-packages/anndata/_core/storage.py:39: ImplicitModificationWarning: X should not be a np.matrix, use np.ndarray instead.\n",
      "  warnings.warn(msg, ImplicitModificationWarning)\n",
      "/Users/frederik/Repositories/Leipzig_big_data_praktikum_gene_expression_autoencoder/autoCell/data_loader.py:138: ImplicitModificationWarning: Modifying `X` on a view results in data being overridden\n",
      "  self.adata.X = X\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 1000 cells × 61888 genes\n"
     ]
    }
   ],
   "source": [
    "dataset = SingleCellDataset(\n",
    "    file_path=\"data.h5ad\",\n",
    "    cell_subset=[i for i in range(1000)],\n",
    "    log_transform=True,\n",
    "    normalize=True,\n",
    "    scale_factor=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \n",
      "tensor(1502.2156)\n",
      "torch.Size([1, 61888])\n",
      "tensor(1.)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "1: \n",
      "tensor(911.1226)\n",
      "torch.Size([1, 61888])\n",
      "tensor(1.)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "2: \n",
      "tensor(855.3485)\n",
      "torch.Size([1, 61888])\n",
      "tensor(1.)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "3: \n",
      "tensor(899.4514)\n",
      "torch.Size([1, 61888])\n",
      "tensor(1.)\n",
      "tensor([[0.0000, 0.5384, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "4: \n",
      "tensor(818.5052)\n",
      "torch.Size([1, 61888])\n",
      "tensor(1.)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "5: \n",
      "tensor(865.3433)\n",
      "torch.Size([1, 61888])\n",
      "tensor(1.)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "6: \n",
      "tensor(1318.5415)\n",
      "torch.Size([1, 61888])\n",
      "tensor(1.)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "7: \n",
      "tensor(1082.9573)\n",
      "torch.Size([1, 61888])\n",
      "tensor(1.)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "8: \n",
      "tensor(1569.1642)\n",
      "torch.Size([1, 61888])\n",
      "tensor(1.)\n",
      "tensor([[0.0000, 0.4118, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "9: \n",
      "tensor(898.8785)\n",
      "torch.Size([1, 61888])\n",
      "tensor(1.)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "10: \n",
      "tensor(566.5305)\n",
      "torch.Size([1, 61888])\n",
      "tensor(1.)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "for idx, sample in enumerate(dataloader):\n",
    "    print(f\"{idx}: \")\n",
    "    print(sample.sum())\n",
    "    print(sample.shape)\n",
    "    print(sample.max())\n",
    "    print(sample)\n",
    "    if idx >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = dataset[0]\n",
    "sample2 = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "def elbo_loss_function(recon_x: torch.Tensor, x: torch.Tensor, mu: torch.Tensor, logvar: torch.Tensor, beta: float=1.0):\n",
    "    \"\"\"Uses mean reduction as opposed to summing in the original VAE paper\n",
    "\n",
    "    TODO: evaluate mean vs sum reduction\n",
    "    \"\"\"\n",
    "    if logvar is None:\n",
    "        logvar = torch.ones_like(mu)\n",
    "    \n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    print(BCE)\n",
    "    print(KLD)\n",
    "\n",
    "    return BCE + beta * KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(39353.0469)\n",
      "tensor(0.8591)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(39353.9062)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elbo_loss_function(sample1, sample2, torch.Tensor([1.0]), torch.Tensor([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "def vae_loss(x, x_decoded_mean, in_dim, var_, z_log_var, z_mean):\n",
    "                xent_loss = in_dim * keras.metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "                if var_:\n",
    "                    kl_loss = - 0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "                else:\n",
    "                    kl_loss = - 0.5 * tf.reduce_sum(1 + 1 - tf.square(z_mean) - tf.exp(1.0), axis=-1)\n",
    "\n",
    "                print(xent_loss)\n",
    "                print(kl_loss)\n",
    "                return tf.reduce_mean(xent_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = tf.convert_to_tensor(sample1.numpy())\n",
    "tensor2 = tf.convert_to_tensor(sample2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(16710.162, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8591409, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=16711.021484375>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_loss(tensor1, tensor2, len(tensor2), True, tf.convert_to_tensor([1.0]), tf.convert_to_tensor([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "biase = pd.read_csv(\"biase.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69314718])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log1p([1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GSM1377859    11.931624\n",
       "GSM1377860    11.227484\n",
       "GSM1377861    10.835056\n",
       "GSM1377862    11.658470\n",
       "GSM1377863    11.937874\n",
       "GSM1377864    12.529428\n",
       "GSM1377865    11.865965\n",
       "GSM1377866    11.022527\n",
       "GSM1377867    12.017080\n",
       "GSM1377868    11.572478\n",
       "GSM1377869    11.073064\n",
       "GSM1377870    11.014299\n",
       "GSM1377871    13.280945\n",
       "GSM1377872    11.918465\n",
       "GSM1377873    11.931277\n",
       "GSM1377874    11.457063\n",
       "GSM1377875    13.050027\n",
       "GSM1377876    11.713717\n",
       "GSM1377877    11.508275\n",
       "GSM1377878    12.708573\n",
       "GSM1377879    11.920182\n",
       "GSM1377880    12.992025\n",
       "GSM1377881    12.230150\n",
       "GSM1377882    14.065475\n",
       "GSM1377883    17.889355\n",
       "GSM1377884    11.902398\n",
       "GSM1377885    11.494756\n",
       "GSM1377886    11.253091\n",
       "GSM1377887    12.624400\n",
       "GSM1377888    12.351530\n",
       "GSM1377889    12.144429\n",
       "GSM1377890    11.421407\n",
       "GSM1377891    11.425688\n",
       "GSM1377892    12.090301\n",
       "GSM1377893    11.810989\n",
       "GSM1377894    11.534245\n",
       "GSM1377895    11.317317\n",
       "GSM1377896    11.864407\n",
       "GSM1377897    12.053189\n",
       "GSM1377898    12.676303\n",
       "GSM1377899    12.355995\n",
       "GSM1377900    12.302673\n",
       "GSM1377901    12.435720\n",
       "GSM1377902    14.932884\n",
       "GSM1377903    11.614990\n",
       "GSM1377904    12.483214\n",
       "GSM1377905    12.362481\n",
       "GSM1377906    12.569699\n",
       "GSM1377907    12.255123\n",
       "GSM1377908    12.345513\n",
       "GSM1377909    11.185290\n",
       "GSM1377910    12.899853\n",
       "GSM1377911    11.950326\n",
       "GSM1377912    15.007141\n",
       "GSM1377913    13.482468\n",
       "GSM1377914    14.931615\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biase = biase.T\n",
    "biase.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the variational autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the variational autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
